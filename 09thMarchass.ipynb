{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a2ca86-7cf1-4fa3-8e1b-a1d943a9b572",
   "metadata": {},
   "source": [
    "#Ans.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4e400-7c66-4062-a9aa-2196030968b0",
   "metadata": {},
   "source": [
    "The Probability Mass function(PMF) and Probability Density Function(PDF) are mathematical concepts used in probabilty and statistics to describe the distribution of discrete random variable and a continuous random variable. They help us understand the likelihood of different outcomes or values occuring in a random experiment.\n",
    "\n",
    "1.Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables. It assigns probabilities to each possible outcome of the random variable. In other words, it gives you the probability of each specific value occurring.\n",
    "Mathematically, for a discrete random variable X, the PMF is defined as:\n",
    "P(X=x)\n",
    "\n",
    "Where:\n",
    "\n",
    "x is a specific value that the random variable can take.\n",
    "\n",
    "\n",
    ".P(X=x) is the probability that the random variable  X takes the value  x.\n",
    "Example of PMF:\n",
    "Consider rolling a fair six-sided die. The possible outcomes are 1, 2, 3, 4, 5, and 6. The PMF for this scenario would be:\n",
    "P(X = 1) = 1/6\n",
    "\n",
    "P(X = 2) = 1/6\n",
    "\n",
    "P(X = 3) = 1/6\n",
    "\n",
    "P(X = 4) = 1/6\n",
    "\n",
    "P(X = 5) = 1/6\n",
    "\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "2.Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables. Since continuous variables can take on an infinite number of values within a range, the concept of assigning probabilities to individual values is not applicable. Instead, the PDF gives you the probability that the random variable falls within a specific interval.\n",
    "Mathematically, for a continuous random variable X, the PDF is defined as:\n",
    "f(x)\n",
    "\n",
    "Where:\n",
    "\n",
    "\n",
    ".x is a specific value within the range of the random variable.\n",
    "\n",
    "\n",
    ".f(x) is the probability density at the value x. The area under the PDF over a certain interval gives the probability that the random variable falls within that interval.\n",
    "\n",
    "Example of PDF:\n",
    "\n",
    "Consider the height of individuals. Heights are a continuous random variable. Let's say the height of adults in a certain population follows a normal distribution with a mean of 170 cm and a standard deviation of 10 cm. The PDF for this scenario would be described by the normal distribution curve, where different values of x correspond to different probabilities of height occurrences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0ab15-2f86-42a8-8db0-b1a53521c350",
   "metadata": {},
   "source": [
    "#Ans.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f4776-9460-4c22-ba0e-9a2a55726802",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a concept in probability and statistics that provides information about the probability of a random variable taking on a value less than or equal to a given value. In other words, it gives you the cumulative probability distribution up to a certain point. The CDF is defined for both discrete and continuous random variables.\n",
    "\n",
    "Mathematically, for a random variable X, the CDF is denoted as \n",
    "F(x) and is defined as follows:\n",
    "\n",
    "For a discrete random variable:\n",
    "\n",
    "\n",
    "F(x)=P(X≤x)\n",
    "\n",
    "For a continuous random variable:\n",
    "\n",
    "\n",
    "F(x)=∫ \n",
    "−∞\n",
    "x\n",
    "​\n",
    " f(t)dt\n",
    "\n",
    "Where:\n",
    "\n",
    "x is a specific value of the random variable.\n",
    "\n",
    "\n",
    "f(t) is the Probability Density Function (PDF) of the continuous random variable at \n",
    "\n",
    "\n",
    "t.\n",
    "The integral represents the area under the PDF curve from negative infinity to \n",
    "\n",
    "\n",
    "x.\n",
    "Example of CDF:\n",
    "Let's use the example of rolling a fair six-sided die. The CDF for this scenario can be calculated as follows:\n",
    "\n",
    "For the discrete random variable X representing the outcome of rolling the die:\n",
    "\n",
    "\n",
    "F(x)=P(X≤x)\n",
    "\n",
    "For x=1:\n",
    "\n",
    "f(1) = P(X<=1) = P(X = 1) = 1/6\n",
    " \n",
    "\n",
    "For x=2:\n",
    "\n",
    "F(2) =  P(X<=2) = P(X = 1) + P(X =  2) = 1/6 + 1/6 + 1/3\n",
    "\n",
    "And so on for the other values of x.\n",
    "\n",
    "Why CDF is used:\n",
    "The CDF is used for several reasons:\n",
    "\n",
    "1.Probability Calculations: The CDF provides a way to calculate probabilities associated with a range of values. For example, you can find the probability that a random variable falls between two values by subtracting the CDF value at the lower value from the CDF value at the higher value.\n",
    "\n",
    "2.Quantile Estimation: CDF allows you to find the value corresponding to a specific probability. This is useful for determining percentiles or quantiles of a distribution.\n",
    "\n",
    "3.Comparing Distributions: CDFs are a convenient way to compare different probability distributions. By plotting multiple CDFs on the same graph, you can visually compare how different variables or populations behave.\n",
    "\n",
    "4.Modeling and Analysis: CDFs help in analyzing and modeling real-world phenomena by characterizing the behavior of random variables and understanding how likely certain outcomes are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906738f-9626-43b7-94f2-24b0607c7a5e",
   "metadata": {},
   "source": [
    "#Ans3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db02456-f590-4bd2-a1c7-4b73a12c30a3",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, is one of the most commonly used probability distributions in statistics. It is used to model a wide range of natural phenomena and real-world situations. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1.Height of Individuals: The heights of adult humans often follow a normal distribution. The parameters of the distribution, namely the mean and standard deviation, determine the average height and how much variability there is in height among the population.\n",
    "\n",
    "2.Test Scores: In educational testing, the scores of a large group of students on a standardized test often approximate a normal distribution. The mean and standard deviation of the distribution provide insights into the average performance and spread of scores.\n",
    "\n",
    "3.Errors in Measurements: Many measurement errors in scientific experiments can be approximated by a normal distribution. The mean error might be close to zero (indicating unbiased measurements), and the standard deviation could reflect the precision of the measurement instrument.\n",
    "\n",
    "4.Financial Data: Stock prices, returns, and other financial variables often exhibit behavior that can be approximated by a normal distribution, particularly over short time intervals. The mean and standard deviation are crucial for understanding the average returns and volatility of investments.\n",
    "\n",
    "5.IQ Scores: Intelligence quotient (IQ) scores are often modeled using a normal distribution. The mean IQ is typically set to 100, and the standard deviation indicates the spread of scores around the mean.\n",
    "\n",
    "6.Natural Phenomena: Many natural phenomena, such as the distribution of particle velocities in a gas or the distribution of reaction times in humans, can be approximated by a normal distribution under certain conditions.\n",
    "\n",
    "The parameters of the normal distribution—the mean (μ) and the standard deviation (σ)—play a significant role in shaping the distribution:\n",
    "\n",
    "1.Mean (μ): The mean is the central value of the distribution. It determines the location of the peak of the bell curve. When μ is increased or decreased, the entire curve shifts to the right or left along the x-axis.\n",
    "\n",
    "2.Standard Deviation (σ): The standard deviation controls the spread or dispersion of the distribution. A smaller σ results in a narrower curve, while a larger σ leads to a wider curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e32240-b548-4a68-844f-9165389320f1",
   "metadata": {},
   "source": [
    "#Ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d5711e-5a43-4134-8c3b-782fba4c0aae",
   "metadata": {},
   "source": [
    "The Normal Distribution holds significant importance in various fields of science, statistics, and practical applications due to its mathematical properties and its frequent occurrence in real-world phenomena. Some key reasons for the importance of the Normal Distribution include:\n",
    "\n",
    "Central Limit Theorem: The Normal Distribution is closely tied to the Central Limit Theorem, which states that the sum (or average) of a large number of independent, identically distributed random variables will have a distribution that approaches a normal distribution, regardless of the original distribution of the variables. This property makes the Normal Distribution a fundamental concept in inferential statistics.\n",
    "\n",
    "Statistical Inference: Many statistical methods and hypothesis tests are based on the assumption of normality. When data follows a normal distribution, it simplifies statistical analysis, allowing for accurate estimation of parameters, confidence intervals, and hypothesis testing.\n",
    "\n",
    "Modeling and Prediction: In many cases, the Normal Distribution serves as a good approximation for the distribution of real-world data. This enables scientists, engineers, and analysts to develop accurate models and make predictions about various phenomena, ranging from weather patterns to financial markets.\n",
    "\n",
    "Parameter Estimation: The properties of the Normal Distribution make it easier to estimate its parameters, such as the mean and standard deviation, from sample data. These estimated parameters can provide valuable insights into the underlying population.\n",
    "\n",
    "Risk Management: In finance and risk assessment, the Normal Distribution is often used to model asset returns and risk factors. This allows for the calculation of probabilities of extreme events and helps with portfolio optimization and risk management strategies.\n",
    "\n",
    "Quality Control: In manufacturing and quality control processes, the Normal Distribution is used to assess the variability of products and identify defects. Deviations from normality can indicate potential issues in the production process.\n",
    "\n",
    "Biological and Social Sciences: Many biological characteristics, such as height, weight, and IQ, tend to follow a normal distribution. Social phenomena like test scores, income distribution, and reaction times also often exhibit normal distribution traits.\n",
    "\n",
    "Real-Life Examples of Normal Distribution:\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores of a large population often follow a normal distribution. The mean IQ is typically set to 100, and the standard deviation indicates the spread of scores around the mean.\n",
    "\n",
    "Height: The heights of adult individuals within a population often approximate a normal distribution. The mean height and standard deviation determine the average height and variability.\n",
    "\n",
    "Exam Scores: In a large class, the distribution of exam scores might resemble a normal distribution, with a peak around the class average.\n",
    "\n",
    "Temperature: The daily temperature readings in a given location over a long period might be approximately normally distributed, especially if the data collection follows Central Limit Theorem conditions.\n",
    "\n",
    "Financial Returns: Short-term stock returns, especially under certain market conditions, can exhibit behavior close to a normal distribution. This assumption forms the basis for many financial models.\n",
    "\n",
    "Reaction Times: The time it takes for humans to react to a stimulus often follows a normal distribution. This is commonly observed in psychological experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be400c-675c-4fbd-b6c8-8b3c8da835a5",
   "metadata": {},
   "source": [
    "#Ans.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f45cdc-2eaf-4cd8-a25b-d2284557c5cb",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually denoted as \"1\") and failure (usually denoted as \"0\"). It's named after the Swiss mathematician Jacob Bernoulli, who introduced it in the 18th century. The distribution is characterized by a single parameter, usually denoted as \"p,\" which represents the probability of success.\n",
    "\n",
    "Mathematically, the probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1 - x)\n",
    "\n",
    "where:\n",
    "\n",
    "X is a random variable representing the outcome (0 or 1).\n",
    "x is the specific outcome (0 or 1).\n",
    "p is the probability of success.\n",
    "\n",
    "An example of a Bernoulli distribution is modeling the outcome of flipping a fair coin. If we define \"success\" as getting heads (H) and \"failure\" as getting tails (T), the Bernoulli distribution can be used to describe the probability of getting heads (success) in a single coin flip.\n",
    "\n",
    "Now, moving on to the difference between Bernoulli and Binomial distributions:\n",
    "\n",
    "1.Number of Trials:\n",
    "\n",
    "Bernoulli Distribution: Represents a single trial or experiment with two possible outcomes (success or failure).\n",
    "Binomial Distribution: Represents the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "2.Parameters:\n",
    "\n",
    "Bernoulli Distribution: Has a single parameter, p, which is the probability of success in a single trial.\n",
    "\n",
    "Binomial Distribution: Has two parameters, n and p, where n is the number of trials and p is the probability of success in each trial.\n",
    "\n",
    "3.Probability Mass Function:\n",
    "\n",
    "Bernoulli Distribution: Describes the probability of a single outcome (0 or 1) in a single trial.\n",
    "\n",
    "Binomial Distribution: Describes the probability of getting k successes out of n trials, where k can range from 0 to n.\n",
    "\n",
    "4.Use Cases:\n",
    "\n",
    "Bernoulli Distribution: Often used to model simple binary events like coin flips, where there's only one trial.\n",
    "\n",
    "Binomial Distribution: Used to model scenarios where you have a fixed number of independent trials, and you're interested in the number of successes among those trials. For example, counting the number of heads in multiple coin flips or the number of defective items in a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86018158-dc99-4d33-aeb8-5a0ad0441f50",
   "metadata": {},
   "source": [
    "#Ans.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7e150-f8a4-4021-8ce8-146003dced21",
   "metadata": {},
   "source": [
    "Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n",
    "\n",
    "To calculate the probability that a randomly selected observation from a normally distributed dataset will be greater than 60, we can use the Z-score formula and the standard normal distribution (also known as the Z-distribution). The formula for calculating the Z-score is:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "Where:\n",
    "\n",
    "X is the value for which we want to find the probability (in this case, X = 60).\n",
    "μ is the mean of the dataset (μ = 50).\n",
    "σ is the standard deviation of the dataset (σ = 10).\n",
    "Z is the Z-score.\n",
    "Once we calculate the Z-score, we can use a standard normal distribution table or calculator to find the corresponding cumulative probability (often denoted as P(Z > z)).\n",
    "\n",
    "Let's perform the calculations step by step:\n",
    "\n",
    "Calculate the Z-score:\n",
    "Z = (60 - 50) / 10 = 1\n",
    "\n",
    "Look up the cumulative probability for the Z-score of 1:\n",
    "Using a standard normal distribution table or calculator, you can find that P(Z > 1) is approximately 0.1587.\n",
    "\n",
    "So, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587, or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622fee9f-8f24-410a-bf61-a1e731f3effc",
   "metadata": {},
   "source": [
    "#Ans.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b37922-6091-49cf-b15d-70f16cd6042e",
   "metadata": {},
   "source": [
    "The uniform distribution is a type of probability distribution that describes a situation where all values within a certain range are equally likely to occur. In other words, it's a distribution where every possible outcome has the same probability of happening. The uniform distribution is often depicted as a flat and constant probability density function (PDF) over the specified interval.\n",
    "\n",
    "Mathematically, for a continuous uniform distribution over the interval [a, b], the probability density function is given by:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "0 otherwise\n",
    "\n",
    "Where:\n",
    "\n",
    "a is the lower bound of the interval.\n",
    "\n",
    "b is the upper bound of the interval.\n",
    "\n",
    "f(x) is the probability density function.\n",
    "\n",
    "For a discrete uniform distribution over the set {a, a+1, ..., b}, the probability mass function (PMF) is given by:\n",
    "\n",
    "P(X = x) = 1 / (b - a + 1) for a ≤ x ≤ b\n",
    "\n",
    "0 otherwise\n",
    "\n",
    "Here's an example to illustrate the uniform distribution:\n",
    "\n",
    "Imagine you have a fair six-sided die. Each side of the die has a number from 1 to 6. If you roll the die, the outcome is uniformly distributed because each face has an equal chance of landing face up. In this case:\n",
    "\n",
    "a = 1 (the lowest possible outcome)\n",
    "\n",
    "b = 6 (the highest possible outcome)\n",
    "\n",
    "For the continuous case, consider a scenario where a random variable X represents the time (in minutes) that it takes for a train to arrive at a station, and you know that trains arrive uniformly between the times 10:00 AM and 11:00 AM. The probability of a train arriving at any specific minute within that interval is the same, creating a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb51c71-77d8-44e0-9a03-4332978ea71b",
   "metadata": {},
   "source": [
    "#Ans.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b134df6-0963-4229-8a0b-08d523849d4c",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a distribution. It's calculated using the formula:\n",
    "\n",
    "Z = x-μ/σ\n",
    "Where:\n",
    "\n",
    ".x is the individual data point.\n",
    "\n",
    ".μ is the mean of the distribution.\n",
    "\n",
    ".σ is the standard deviation of the distribution.\n",
    "\n",
    "The z-score essentially tells you how \"typical\" or \"unusual\" a data point is within the context of its distribution. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that it's below the mean.\n",
    "\n",
    "Importance of the z-score:\n",
    "\n",
    "1.Standardization and Comparison: The z-score standardizes data, allowing for meaningful comparisons between data points from different distributions with varying means and standard deviations. This is particularly useful when dealing with diverse datasets or when comparing values from different contexts.\n",
    "\n",
    "2.Identifying Outliers: Z-scores can help identify outliers, which are data points that significantly deviate from the overall pattern of the data. Outliers often have z-scores that are several standard deviations away from the mean.\n",
    "\n",
    "3.Normalization: Z-scores are commonly used in data preprocessing and normalization. By transforming data into z-scores, variables with different scales can be put on a common scale, making it easier to analyze and interpret them.\n",
    "\n",
    "4.Probability Calculation: Z-scores are used in conjunction with the standard normal distribution (also known as the z-distribution) to calculate probabilities and percentiles. This is especially valuable in hypothesis testing and confidence interval calculations.\n",
    "\n",
    "5.Statistical Testing: Z-scores play a crucial role in hypothesis testing when the sample size is large and the population standard deviation is known. They are used to calculate test statistics and p-values in various tests, such as the z-test for means.\n",
    "\n",
    "6.Quality Control and Process Improvement: In quality control processes, z-scores can help determine whether a process is operating within acceptable limits. Deviations from the mean beyond a certain threshold (measured in z-scores) can signal the need for corrective action.\n",
    "\n",
    "7.Data Interpretation: Z-scores provide context for individual data points, indicating whether they are relatively close to or far from the center of the distribution. This aids in the interpretation of data and helps in drawing meaningful conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ed44b-6eaa-4f84-ba5b-02594da60a85",
   "metadata": {},
   "source": [
    "#Ans9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1d7ea-2866-4a0e-bc8d-f25a1d22a271",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample means of a large number of independent and identically distributed random variables. In simpler terms, it states that when you take a sufficiently large number of random samples from any population, the distribution of the sample means will tend to follow a normal (Gaussian) distribution, regardless of the original distribution of the population.\n",
    "\n",
    "Key points of the Central Limit Theorem:\n",
    "\n",
    "Sample Size Independence: The samples taken should be independent of each other and should be of the same size.\n",
    "\n",
    "Sample Size: As the sample size increases, the distribution of sample means becomes more and more normal, even if the underlying population distribution is not normal.\n",
    "\n",
    "Identically Distributed: The random variables in each sample should be drawn from the same population distribution.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "1.Approximation of Distributions: The CLT is of great significance because it allows us to approximate the distribution of sample means, regardless of the original population distribution. This is extremely useful since the normal distribution is well-understood and has many mathematical properties that make statistical analysis easier.\n",
    "\n",
    "2.Basis for Inference: Many statistical tests and methods are based on the assumption of normality. The CLT justifies this assumption in situations where the sample size is sufficiently large, even if the population distribution is not normal.\n",
    "\n",
    "3.Real-world Application: The CLT is widely applicable across various fields, from natural sciences to social sciences and economics. It helps researchers and analysts make reasonable assumptions about the behavior of sample means, making it easier to draw conclusions and make predictions from data.\n",
    "\n",
    "4.Sampling Theory: The CLT forms the foundation of sampling theory. It's the reason why random sampling is often preferred in research, as it allows us to make inferences about a population based on the characteristics of a smaller sample.\n",
    "\n",
    "5.Quality Control: In manufacturing and quality control, the CLT is used to assess the consistency and quality of products by analyzing sample means.\n",
    "\n",
    "Estimation and Confidence Intervals: The CLT is essential for constructing confidence intervals and estimating population parameters from sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f10af-8a06-4a3d-8c81-ff21c0fdb871",
   "metadata": {},
   "source": [
    "#Ans10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551554e4-deff-4c24-917b-ae2369d1851f",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a powerful statistical concept, but it relies on certain assumptions in order to hold true. These assumptions ensure that the sample means converge to a normal distribution as the sample size increases. The main assumptions of the Central Limit Theorem are:\n",
    "\n",
    "Independence: The sampled observations should be independent of each other. In other words, the value of one observation should not affect the value of another observation.\n",
    "\n",
    "Random Sampling: The samples should be drawn randomly from the population. This ensures that the sample is representative of the entire population and helps prevent bias.\n",
    "\n",
    "Sample Size: The sample size should be sufficiently large. While there isn't an exact threshold, a commonly used guideline is that the sample size should be at least 30. However, the larger the sample size, the more robust the convergence to a normal distribution.\n",
    "\n",
    "Identically Distributed: The sampled observations should come from the same population and should have the same distribution, regardless of the population distribution itself.\n",
    "\n",
    "Finite Variance: The population from which the samples are drawn should have a finite variance. This assumption is important to ensure that the sample means don't become too spread out.\n",
    "\n",
    "It's important to note that while these assumptions are crucial for the CLT to apply, the theorem is quite robust. In many real-world scenarios, even if some of the assumptions are slightly violated, the CLT can still provide a reasonable approximation. However, for rigorous statistical analysis and hypothesis testing, it's best to strive for adherence to these assumptions as closely as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f44fe-2f32-45ab-9dc4-c0ebd322ed34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
